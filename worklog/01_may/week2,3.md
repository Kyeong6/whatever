## Setting

### ìˆœì„œ

1. conda ì„¤ì¹˜(python ê°€ìƒí™˜ê²½ ì œê³µ)
2. LSTM_pipline ë””ë ‰í† ë¦¬ ì´ë™

```bash
# ì´ë™
cd /{user_path}/LSTM_pipeline
```

1. LSTM_pipeline ê°€ìƒí™˜ê²½ ì„¤ì¹˜

```bash
conda env create -f lstm_env.yaml
```

MAC OSì—ì„œëŠ” `PackagesNotFoundError: The following packages are not available from current channels:` ë°œìƒ

í•´ë‹¹ ì˜¤ë¥˜ëŠ” Guidelineì—ì„œ ì„¤ëª…í•˜ëŠ” OSëŠ” Windowì´ê¸° ë•Œë¬¸ì— MAC OSì— í˜¸í™˜ë˜ê²Œ yaml íŒŒì¼ ìˆ˜ì •ì´ í•„ìš”í•˜ë‹¤. 

**MAC OSì— í˜¸í™˜ë˜ëŠ” lstm_env.yaml ìˆ˜ì •ë³¸**

```yaml
name: lstm_env
channels:
  - conda-forge
  - defaults
dependencies:
  - python=3.9
  - ipykernel
  - ipython
  - ipywidgets
  - jupyter
  - jupyter_client
  - jupyter_console
  - jupyter_core
  - jupyterlab
  - matplotlib
  - numpy
  - pandas
  - scipy
  - tensorflow=2.10.0
  - h5py
  - keras=2.10.0
  - scikit-learn
  - seaborn
  - pillow
  - requests
  - pyyaml
  - protobuf
  - libclang
  - aiohttp
  - async-timeout
  - attrs
  - bcrypt
  - beautifulsoup4
  - bleach
  - cffi
  - charset-normalizer
  - cryptography
  - decorator
  - defusedxml
  - gast
  - grpcio
  - idna
  - importlib-metadata
  - markdown
  - oauthlib
  - openssl
  - pandas
  - parso
  - pickleshare
  - prompt-toolkit
  - pygments
  - pyjwt
  - pyparsing
  - pyrsistent
  - python-dateutil
  - pytz
  - requests
  - rsa
  - setuptools
  - six
  - sqlite
  - tensorboard
  - termcolor
  - tornado
  - typing_extensions
  - urllib3
  - wheel
  - widgetsnbextension
  - zipp

prefix: /Users/{username}/anaconda3/envs/lstm_env
```

prefixëŠ” condaì„¤ì¹˜ ê²½ë¡œë¥¼ ì‘ì„±í•˜ë©´ ëœë‹¤.

1. lstm_env í™œì„±í™”

```bash
conda activate lstm_env
```

---

## 1_Preprocessing_tool.py

### ì‹¤í–‰ ëª…ë ¹ì–´

```bash
python 1_Preprocessing_tool.py -f /Users/kyeong6/Desktop/github_submit/WVR/LSTM_pipeline/Input/sample.csv -p
```

### **arguments**

- -h : parse_arguments()ì˜ ì¸ìë“¤ì— ëŒ€í•œ ì„¤ëª… ì¶œë ¥(help ê¸°ëŠ¥)
- -f : filenameì„ ì…ë ¥, ì¦‰ Input ë””ë ‰í† ë¦¬ì— ìœ„ì¹˜í•œ ì‹œê³„ì—´ ë°ì´í„°(time, valueë¡œ êµ¬ì„±)ë¥¼ ì…ë ¥ íŒŒì¼ë¡œ ì„¤ì •
- -n : normal_rangeì˜ ì˜ë¯¸ë¡œ ì •ìƒë²”ìœ„ë¥¼ ì •í•¨(ê¸°ë³¸ê°’ ì¡´ì¬)
- -m1 : minì„ ì˜ë¯¸í•˜ë©°, ì •ìƒ ë²”ìœ„ì˜ ìµœì†Ÿê°’ì„ ì§€ì •í•œë‹¤.
- -m2 : maxë¥¼ ì˜ë¯¸í•˜ë©°, ì •ìƒ ë²”ìœ„ì˜ ìµœëŒ“ê°’ì„ ì§€ì •í•œë‹¤.
- -l : levelì˜ ì˜ë¯¸ë¡œ ì´ìƒì¹˜ ë³´ì •ì‹œ, ì •ìƒë²”ìœ„ì—ì„œì˜ ì´ìƒì¹˜ í—ˆìš© ê¸°ì¤€(ê¸°ë³¸ê°’ 10% ì¡´ì¬)
- -w : weekì˜ ì˜ë¯¸ë¡œ ì£¼ë§ í˜¹ì€ í‰ì¼ ë°ì´í„° ì €ì¥(ê¸°ë³¸ê°’ all)
- -t : timeì˜ ì˜ë¯¸ë¡œ ì‹œê°„ ê°„ê²©ì„ ì¡°ì •
    - hourly : ì‹œê°„ë‹¹
    - daily : ì¼ë‹¹
- -p : preprocessì˜ ì˜ë¯¸ë¡œ íŠ¹ì •í•œ ì¸ìì˜ ê°’ìœ¼ë¡œ ë°ì´í„° ì „ì²˜ë¦¬ ì§„í–‰(-f ì…ë ¥ í•„ìš”)
    - -fë¥¼ ì…ë ¥í•˜ë©´ ë‹¤ë¥¸ ì¸ìë“¤ì€ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹¤í–‰

í•´ë‹¹ íŒŒì¼ì€ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ CLI ë„êµ¬ ì—­í• ì„ í•œë‹¤. argparse ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ëª…ë ¹ì¤„ ì˜µì…˜ ì •ì˜ ë° parsingí•˜ë©°, Data_preprocessing ëª¨ë“ˆ í•¨ìˆ˜ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë°ì´í„° ì‘ì—… ìˆ˜í–‰

### main() í•¨ìˆ˜

- `preprocessing = importlib.import_module('Data_preprocessing')` ì‘ì„±í•œ ì´ìœ 
    - `Data_preprocessing.py`ë¥¼ ì°¸ì¡°í•˜ì—¬ main()ê°€ ì‹¤í–‰

- main()

```python
def main():
    args = parse_arguments()

    if not args.preprocess: 
        # ë°ì´í„° ì½ì–´ì˜¤ê¸°
        df = preprocessing.read_data(args.filename) 
        # # ê²°ì¸¡ì¹˜ ë³´ì •
        df = preprocessing.Missing(df) 

        if args.time is not None: 
            # ì‹œê°„ ê°„ê²© ë³‘í•©
            time_interval = {'hourly': '1H', 'daily': '1D'}.get(args.time)
            df = preprocessing.TimeIntervalData(df,time_interval)

        if args.normal_range:
            # ì´ìƒì¹˜ ë³´ì •
            df, table = preprocessing.Anomalous(df, args.level, args.max, args.min)

        # í‰ì¼ / ì£¼ë§ ë°ì´í„° êµ¬í•˜ê¸°    
        if args.week in ['weekday', 'weekend']:
            df = preprocessing.week(df,args.week)

        # ì „ì²˜ë¦¬í•œ ë°ì´í„° ì €ì¥
        preprocessing.save_data(df, table)
    else:
        # ë°ì´í„° ì „ì²˜ë¦¬ : ì‹œê°„ ë³‘í•©(daily), ì´ìƒì¹˜ ë³´ì •(level: 10%, ì •ìƒë²”ìœ„: UIF or LIF), ì „ì²´ ë°ì´í„°(week: all)
        preprocessing.Data_preprocessing(args.filename, args.level)
```

- `if not args.preprocess` ì¡°ê±´ë¬¸
    - ìœ„ parser.add_argumentì˜ -p ì˜µì…˜ì— í•´ë‹¹í•˜ëŠ” --preprocessê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ë•Œ ì‹¤í–‰í•¨ì„ ì˜ë¯¸í•œë‹¤. ì¦‰, ì‚¬ìš©ìê°€ input dataì˜ ì „ì²˜ë¦¬ë¥¼ ì„¸ë¶€ì ìœ¼ë¡œ ì œì–´í•˜ê³ ì í•  ë•Œ ì¡°ê±´ë¬¸ ë¸”ë¡ ë‚´ì˜ ì½”ë“œê°€ ì‹¤í–‰
- `else`
    - --preprocessê°€ ì„¤ì •ëœ ê²½ìš°, ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •ëœ ì¸ìë“¤ë¡œ ë°ì´í„° ì „ì²˜ë¦¬ ìˆ˜í–‰

---

## Data_preprocessing.py

<aside>
ğŸ’¡ 1_Preprocessing_tool.pyì€ Data_preprocessing.pyë¥¼ importí•˜ì—¬ CLIë¥¼ ì§„í–‰í•œë‹¤. 
ë”°ë¼ì„œ Data_preprocessing.pyì˜ main()ì˜ íë¦„ì— ë§ê²Œ ì •ë¦¬ê°€ í•„ìš”í•˜ë‹¤.

</aside>

### ìˆœì„œ

1. ë°ì´í„° ì½ì–´ì˜¤ê¸°(Inputì˜ time/values)
2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
3. ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë³‘í•©(hourly, daily)
4. ì´ìƒì¹˜ ë³´ì •
5. í‰ì¼ê³¼ ì£¼ë§ ë°ì´í„° ì¶”ì¶œ(ì„ íƒ)
6. ì „ì²˜ë¦¬í•œ ë°ì´í„°, ì›ë³¸ ë°ì´í„°ì˜ í†µê³„ í…Œì´ë¸” ì €ì¥
    1. ê²½ë¡œ : ./Output/Data_preprocessing

### í™˜ê²½ ì„¤ì •

```python
import os
import pandas as pd
import sys

os.chdir(os.path.dirname(__file__))
```

- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
- `os.chdir(os.path.dirname(__file__))`
    - __file__ : í˜„ì¬ íŒŒì¼ pathë¥¼ ë°˜í™˜
    - os.path.dirname(__file__) : í˜„ì¬ íŒŒì¼ pathì˜ ë””ë ‰í† ë¦¬ëª… ë°˜í™˜
    - os.chdir(os.path.dirname(__file__))
        - scriptê°€ ì‹¤í–‰ë˜ëŠ” ë””ë ‰í† ë¦¬ë¥¼ script fileì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ë¡œ ë³€ê²½
        
        â†’ ìƒëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•  ë•Œ ë¬¸ì œê°€ ì—†ë„ë¡ í•´ì¤Œ(í˜‘ì—…ì‹œ ë¬¸ì œ x)
        

### ë°ì´í„° ì½ê¸°(read_data)

```python
def read_data(file_name):
    df = pd.read_csv(file_name,index_col = 0) 

    # ë°ì´í„°í”„ë ˆì„ ì¸ë±ìŠ¤ë¥¼ ë°ì´íŠ¸íƒ€ì„ì¸ë±ìŠ¤ë¡œ ë³€í™˜
    df.index = pd.to_datetime(df.index)
    df.index.name = 'time'

    # values ì´ë¦„ ì¶”ì¶œ
    col = df.columns[0]

    # float ë³€í™˜
    df[col] = pd.to_numeric(df[col], errors='coerce') 
    df[col] = df[col].astype(float)
    
    # ì¸ë±ìŠ¤ ì •ë ¬
    df = df.sort_index(ascending=True) 
    return df

```

- df ì„¤ì • â†’ 1_Preprocessing_tool.pyì—ì„œ -f ì¸ìë¥¼ ì´ìš©í•˜ì—¬ ì…ë ¥í•œ íŒŒì¼ëª…
- íŒŒì¼ì— ì¡´ì¬í•˜ëŠ” ê°’ë“¤ ê°ê° `datetime`, `float` ìœ¼ë¡œ íƒ€ì… ë³€í™˜ ì§„í–‰ í›„ ì¸ë±ìŠ¤ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
- df ë°˜í™˜

**1_Preprocessing_tool.py**

```python
def main():
    args = parse_arguments()

    if not args.preprocess: 
        # ë°ì´í„° ì½ì–´ì˜¤ê¸°
        df = preprocessing.read_data(args.filename)
```

í•´ë‹¹ ë¶€ë¶„ê¹Œì§€ ì§„í–‰

### ê²°ì¸¡ì¹˜ ë³´ì •(Missing)

- ì—°ì†ì ì¸ ê²°ì¸¡ì¹˜ 3ê°œ ì´í•˜ì´ë©´ ì´ì „ì˜ ê°’ ëŒ€ì²´, ì´ˆê³¼ì´ë©´ ì„ í˜• ë³´ê°„ì„ ì‚¬ìš©í•˜ì—¬ ê²°ì¸¡ì¹˜ë¥¼ ì±„ì›€

```python
def Missing(df):
    n = 0
    first_column = df.iloc[:, n]

    # in case first line is null
    if first_column.isnull().iloc[0]:
        first_non_nan_index = first_column.first_valid_index()
        df = df.loc[first_non_nan_index:]

    # in case last lines are missing
    nan_list = list(first_column.isnull())
    if nan_list[-1]:
        last_non_nan_idx = first_column.last_valid_index()
        df = df.loc[:last_non_nan_idx]

    # in case greater than 3
    method_fill = 'ffill'  # replace previous values
    count = 0
    for i, v in enumerate(first_column.isnull()) : 
        if v:
            count += 1
        else:
            if count > 3:
                df.iloc[i - count-1:i+1, n] = df.iloc[i - count-1:i+1, n].interpolate()  # replace with interpolation
            else: # in case missing values are less than equal to 3
                df.iloc[i - count-1:i, n].fillna(method=method_fill, inplace=True)
            count = 0
   
    return df
```

- ì²« ë²ˆì§¸ ì¡°ê±´ë¬¸(if first_column.isnull().iloc[0]) : ì²« í–‰ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    - ì²« í–‰ì´ ë§Œì•½ ê²°ì¸¡ì¹˜ë¼ë©´ ê²°ì¸¡ì¹˜ê°€ ì•„ë‹Œ ì²« í–‰ì„ ì°¾ì•„ì„œ ê·¸ í–‰ ì´í›„ ë°ì´í„°ë§Œ ìœ ì§€
    - **ì„ í˜•ë³´ê°„ë²•ì—ì„œ ì²«ë²ˆì§¸ ì ì— í•´ë‹¹**
- ë‘ ë²ˆì§¸ ì¡°ê±´ë¬¸(if nan_list[-1]) : ë§ˆì§€ë§‰ í–‰ ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    - ë§ˆì§€ë§‰ í–‰ì´ ë§Œì•½ ê²°ì¸¡ì¹˜ë¼ë©´ ê²°ì¸¡ì¹˜ê°€ ì•„ë‹Œ ìœ íš¨í•œ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ë¥¼ ì°¾ì•„ í•´ë‹¹ í–‰ê¹Œì§€ ë°ì´í„°ë§Œ ìœ ì§€
    - **ì„ í˜•ë³´ê°„ë²•ì—ì„œ ë§ˆì§€ë§‰ ì ì— í•´ë‹¹**
- enumerateë¥¼ ì´ìš©í•´ null ê°’ count ì§„í–‰(ê²°ì¸¡ì¹˜ ê°’ ì¹´ìš´íŠ¸)
- ì—°ì†ëœ ê²°ì¸¡ì¹˜ 3ê°œ ì´ˆê³¼(if count > 3)
    - í•´ë‹¹ ë²”ìœ„ì— ëŒ€í•´ ì„ í˜• ë³´ê°„(interpolate) ì§„í–‰í•˜ì—¬ ê²°ì¸¡ì¹˜ ì±„ì›€
- ì—°ì†ëœ ê²°ì¸¡ì¹˜ 3ê°œ ì´í•˜(else)
    - method_fillì˜ ê°’ì¸ ffill, ì¦‰ ê²°ì¸¡ì¹˜ë¥¼ ì´ì „ ê°’ì„ ì‚¬ìš©í•´ ì±„ì›€

### ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë³‘í•©

```python
def TimeIntervalData(df,time_interval): 

    time_df = df.sort_index(ascending=True)
    time_df = time_df.resample(time_interval).mean() # í‰ê· ê°’ìœ¼ë¡œ ë³‘í•©

    # timeì˜ ê²°ì¸¡ì¹˜ í™•ì¸
    if time_df.isnull().any().any():
        time_df = Missing(time_df) 

    return time_df
```

- ë°ì´í„°ë¥¼ ì§€ì •ëœ ì‹œê°„ ê°„ê²©(time_interval)ìœ¼ë¡œ ì¬í‘œë³¸í™”í•˜ê³  ê° ê°„ê²©ì˜ í‰ê· ê°’ ê³„ì‚°
    - ì‹œê°„ ê°„ê²© ì¼ê´€ë˜ê²Œí•˜ì—¬ ë¶„ì„, ëª¨ë¸ë§ì— ì í•©
- 1_Preprocessing_tool.py

```python
if args.time is not None: 
            # ì‹œê°„ ê°„ê²© ë³‘í•©
            time_interval = {'hourly': '1H', 'daily': '1D'}.get(args.time)
            df = preprocessing.TimeIntervalData(df,time_interval)
```

TimeIntervalDataì˜ ë§¤ê°œë³€ìˆ˜ì¸ time_intervalì„ 1_Preprocessing_tool.pyì—ì„œ ì§€ì •ì´ ê°€ëŠ¥í•˜ë‹¤. 

- ê¸°ì¤€
    - hourly : 1H
    - daily : 1D

-t ì¸ìë¥¼ terminalì— ì‘ì„±í•  ë•Œ hourly í˜¹ì€ dailyë¥¼ í•¨ê»˜ ì‘ì„±í•´ì¤˜ì•¼ í•˜ëŠ” ì´ìœ ì´ë‹¤.

```python
# ì˜ˆì‹œ
python 1_Preprocessing_tool.py -t hourly
```

**ì¬í‘œë³¸í™” ì˜ˆì‹œ**

- ê¸°ì¡´ ê°’

```python
                     Value
2024-01-01 00:00:00     44
2024-01-01 00:01:00     47
2024-01-01 00:02:00     64
2024-01-01 00:03:00     67
2024-01-01 00:04:00     67
2024-01-01 00:05:00     9
2024-01-01 00:06:00     83
2024-01-01 00:07:00     21
2024-01-01 00:08:00     36
2024-01-01 00:09:00     87
```

- ì¬í‘œë³¸í™”(ê° ê°„ê²©ì˜ í‰ê· ê°’ ê³„ì‚°)

```python
# 5ë¶„ ê°„ê²©ìœ¼ë¡œ ë°ì´í„° ì¬í‘œë³¸í™” í›„ í‰ê· ê°’ ê³„ì‚°
resampled_df = df.resample('5T').mean()
print(resampled_df)
```

- ë³€í˜•ê°’

```python
                     Value
2024-01-01 00:00:00   57.8
2024-01-01 00:05:00   47.2
```

ì²« ë²ˆì§¸ í–‰ì€ 00:00:00 ~ 00:04:00ì˜ ê°’ì˜ í‰ê· 

ë‘ ë²ˆì§¸ í–‰ì€ 00:05:00 ~ 00:09:00ì˜ ê°’ì˜ í‰ê· 

### ì´ìƒì¹˜ ë³´ì •

- ì…ë ¥ë°›ì€ í¼ì„¼íŠ¸ ê°’ì—ì„œ ë²—ì–´ë‚˜ëŠ” ê°’ ì •ìƒë²”ìœ„ë¡œ ë³´ì •

```python
def Anomalous(df, percent, normal_max=None, normal_min=None): 
    col = df.columns[0]
    
    # ì›ë³¸ ë°ì´í„°ì˜ ìµœëŒ“ê°’, ìµœì†Ÿê°’ ê³„ì‚°
    MAX = df[col].max()        
    MIN = df[col].min()
    
    # ì •ìƒë²”ìœ„ê°€ ì—†ëŠ” ê²½ìš° : UIF, LIF 
    if normal_max is None and normal_min is None: 
        q1 = df[col].quantile(0.25)
        q3 = df[col].quantile(0.75)
        IQR = q3 - q1
        UIF = q3 + (IQR * 1.5)
        LIF = q1 - (IQR * 1.5)
        normal_max = UIF 
        normal_min = LIF
    
    # criteria.csv ìƒì„±
    table = pd.DataFrame({'Values': [ MIN, MAX, normal_min, normal_max] },
                index=['raw_min', 'raw_max', 'normal_min', 'normal_max'])

    # ì´ìƒì¹˜ ë³´ì •
    if normal_max is not None: # ì •ìƒë²”ìœ„ì˜ ìµœëŒ“ê°’ì´ ìˆëŠ” ê²½ìš°
        # U_level ê³„ì‚°
        U_level =  (abs(MAX - normal_max) * (percent * 0.01)) +  normal_max
        table.loc['U_level'] = U_level # tableì—ì„œ U_levelë¥¼ ì¶”ê°€
        
        # ë°ì´í„°ì˜ ìµœëŒ“ê°’ì´ ì •ìƒë²”ìœ„ì˜ ìµœëŒ“ê°’ë³´ë‹¤ í¬ë©´ ì •ìƒë²”ìœ„ì˜ ìµœëŒ“ê°’ìœ¼ë¡œ ëŒ€ì²´ 
        if MAX > normal_max:
            df.loc[df[col] > U_level] = normal_max

    if normal_min is not None: # ì •ìƒë²”ìœ„ì˜ ìµœì†Ÿê°’ì´ ìˆëŠ” ê²½ìš°
        # L_level ê³„ì‚°
        L_level = normal_min - (abs(normal_min - MIN) * (percent * 0.01))   
        table.loc['L_level'] = L_level # tableì—ì„œ L_level ì¶”ê°€

        # ë°ì´í„°ì˜ ìµœì†Ÿê°’ì´ ì •ìƒë²”ìœ„ì˜ ìµœì†Ÿê°’ë³´ë‹¤ í¬ë©´ ì •ìƒë²”ìœ„ì˜ ìµœì†Ÿê°’ìœ¼ë¡œ ëŒ€ì²´ 
        if MIN < normal_min:
            df.loc[df[col] < L_level] = normal_min
           
    return df, table
```

- col = df.columns[0] : valueê°’ ì¡´ì¬
- MIN, MAX : criteria.csvì— ë„£ì„ ê°’
- UIF, LIF : normal_max, normal_minì´ ì§€ì •ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ë°ì´í„°ì˜ 1ì‚¬ë¶„ìœ„, 3ì‚¬ë¶„ìœ„(q1, q3)ì„ ê¸°ë°˜ìœ¼ë¡œ ë‚´ë¶€ ìš¸íƒ€ë¦¬ ê³„ì‚°(ë°ì´í„°ì˜ ì •ìƒì„±)
- 1_Preprocessing_tool.py

```python
python 1_Preprocessing_tool.py -n -m1 -m2
```

-nì„ í†µí•´ ì •ìƒë²”ìœ„(default)ë¡œ ì •í•  ìˆ˜ ìˆê³ , -m1, -m2ë¥¼ í†µí•´ì„œ ì •ìƒë²”ìœ„ ì§€ì • ê°€ëŠ¥

**Anomalous í•¨ìˆ˜ëŠ” normal_max, normal_minì´ `None` ìœ¼ë¡œ ì„¤ì •ë˜ì–´ìˆê¸° ë•Œë¬¸ì— ì§€ì • í•„ìš”**

- ìœ„ ê³¼ì •ì„ ì§„í–‰í•œ í›„ table ìƒì„±
    - tableì€ ./Output/Data_preprocessing/creteria.csvì— ì €ì¥
    - index : raw_min, raw_max, normal_min, normal_max
    - ìœ„ ì¸ë±ìŠ¤ì— ê°ê° ìœ„ ê³¼ì •ì„ í†µí•´ ì–»ì€ MIN, MAX, normal_min, normal_max ê°’ ë„£ìŒ

- ì´ìƒì¹˜ ë³´ì • ì§„í–‰
    - ì •ìƒë²”ìœ„ì˜ ìµœëŒ“ê°’ì´ ìˆëŠ” ê²½ìš°(if normal_max is not None)
        - ì´ìƒì¹˜ ë³´ì • ìˆ˜ì¤€(U_level)ì„ ê³„ì‚°
        - ì‹¤ì œ ìµœëŒ“ê°’(MAX)ì´ ì •ìƒë²”ìœ„ì˜ ìµœëŒ“ê°’ë³´ë‹¤ í¬ë©´ ì •ìƒë²”ìœ„ì˜ ìµœëŒ“ê°’ìœ¼ë¡œ ëŒ€ì²´
    - ì •ìƒë²”ìœ„ì˜ ìµœì†Ÿê°’ì´ ìˆëŠ” ê²½ìš°(if normal_min is not None)
        - ì´ìƒì¹˜ ë³´ì • ìˆ˜ì¤€(L_level)ì„ ê³„ì‚°
        - ì‹¤ì œ ìµœì†Ÿê°’(MIN)ì´ ì •ìƒë²”ìœ„ì˜ ìµœì†Ÿê°’ë³´ë‹¤ í¬ë©´ ì •ìƒë²”ìœ„ì˜ ìµœì†Ÿê°’ìœ¼ë¡œ ëŒ€ì²´

- ì´í›„ df ë° table ë°˜í™˜

**ìœ„ ê³¼ì •ì„ í†µí•´ ìµœëŒ“ê°’ í˜¹ì€ ìµœì†Ÿê°’ì˜ ê°’ë“¤ì´ ë„ˆë¬´ ë†’ê±°ë‚˜ ë‚®ì„ ê²½ìš° ì¡°ì •í•˜ì—¬ ì´ìƒì¹˜ë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŒ**

### í‰ì¼ê³¼ ì£¼ë§ ë°ì´í„° ì¶”ì¶œ

```python
def week(df,day_of_week):
        if day_of_week == 'weekend':
            return df[df.index.dayofweek.isin([5, 6])]  # 5: í† ìš”ì¼, 6: ì¼ìš”ì¼
        
        if day_of_week == 'weekday':
            return df[df.index.dayofweek.isin([0, 1, 2, 3, 4])]  # 0~4: ì›”ìš”ì¼ë¶€í„° ê¸ˆìš”ì¼ê¹Œì§€
```

df.index.dayofweekëŠ” pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ datetime ë°ì´í„° íƒ€ì…ì˜ ê°’ì˜ ìš”ì¼ì„ ë‚˜íƒ€ë‚´ëŠ” ì •ìˆ˜ë¥¼ ë°˜í™˜

| ìš”ì¼ | ì •ìˆ˜ |
| --- | --- |
| ì›”ìš”ì¼ | 0 |
| í™”ìš”ì¼ | 1 |
| ìˆ˜ìš”ì¼ | 2 |
| ëª©ìš”ì¼ | 3 |
| ê¸ˆìš”ì¼ | 4 |
| í† ìš”ì¼ | 5 |
| ì¼ìš”ì¼ | 6 |
- 1_Preprocessing_tool.py

```python
python 1_Preprocessing_tool.py -w weekday
```

weekday : í‰ì¼

weekend : ì£¼ë§

### ë°ì´í„° ì €ì¥

```python
def save_data(df, table):

    # í´ë” ìƒì„±
    output_path = './Output/Data_preprocessing'
    os.makedirs(output_path, exist_ok=True)

    # ì „ì²˜ë¦¬í•œ ë°ì´í„°, ì›ë³¸ ë°ì´í„°ì˜ criteria ì €ì¥
    df.to_csv(f'{output_path}/preprocessed.csv')  
    table.to_csv(f'{output_path}/criteria.csv')
```

ìœ„ ê³¼ì •ë“¤ì„ ì§„í–‰í•œ í›„ì˜ ê²°ê³¼ë¬¼(output)ì„ ì €ì¥

- df :  preprocessed.csv
- table : criteria.csv

### ê¸°ë³¸ê°’ ì‹¤í–‰

<aside>
ğŸ’¡ 1_Preprocessing_tool.pyì—ì„œ if not args.preprocessì˜ else ë¶€ë¶„ ì‹¤í–‰ì‹œí‚¬ ë•Œ ì‚¬ìš©í•˜ëŠ” ê¸°ëŠ¥
 -p ì¸ìë¥¼ ì‚¬ìš©í•˜ë©° ê¸°ë³¸ê°’ì„ ì´ìš©í•´ì„œ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰

</aside>

```python
def Data_preprocessing(file_name, percent):
    
    # ë°ì´í„° ì½ì–´ì˜¤ê¸°
    df = read_data(file_name)

    # ê²°ì¸¡ì¹˜ ë³´ì •
    df = Missing(df)

    # ë°ì´í„° ë³‘í•© (1D)
    time_interval = '1D'
    df = TimeIntervalData(df,time_interval)
    
    # ì´ìƒì¹˜ ë³´ì •
    df, table = Anomalous(df, percent, normal_max=None, normal_min=None)

    # í‰ì¼ / ì£¼ë§ ë°ì´í„° êµ¬í•˜ê¸°
    day_of_week = 'all'
    if day_of_week != 'all':
        df = week(df,day_of_week)

    # ì „ì²˜ë¦¬í•œ ë°ì´í„°, ì›ë³¸ ë°ì´í„°ì˜ criteria ì €ì¥
    save_data(df, table)
```

-p ì¸ìë¡œ ì‹¤í–‰í•  ë•Œ -fë¥¼ ì…ë ¥í•´ì•¼ í•˜ëŠ” ì´ìœ  : Data_preprocessingì˜ ë§¤ê°œë³€ìˆ˜ë¡œ file_name ì¡´ì¬

```python
if __name__ == "__main__":
    file_name = sys.argv[1]
    percent = sys.argv[2]

    Data_preprocessing(file_name, percent)
```

sys.argvë¥¼ í†µí•´ í•´ë‹¹ terminalì˜ ê°’ì´ ê°ê° file_name, percent ë³€ìˆ˜ì— ë‹´ê¸°ê³  Data_preprocessing(ê¸°ë³¸ê°’ ì‹¤í–‰)ì˜ ë§¤ê°œë³€ìˆ˜ ê°’ìœ¼ë¡œ ì‚¬ìš©

**ì°¸ê³ **

sys.argv[0] : íŒŒì¼ëª…

sys.argv ìˆœì„œê°€ ì¡´ì¬í•˜ë¯€ë¡œ -f ì¸ìë¥¼ ë¨¼ì € ì‘ì„±í•œ í›„ -l ì¸ì ì‘ì„±

---

## 2_Learning_LSTM.py

Data_preprocessingì„ í†µí•´ ì–»ì€ `criteria.csv`, `peprocessed.csv` ì„ ì´ìš©í•˜ì—¬ ì‹œê³„ì—´ ë¶„ì„ ëª¨ë¸ì¸ `LSTM` ì„ ì‹¤í–‰í•œë‹¤.

### **arguments**

- -h : parse_arguments()ì˜ ì¸ìë“¤ì— ëŒ€í•œ ì„¤ëª… ì¶œë ¥(help ê¸°ëŠ¥)
- -f : ì „ì²˜ë¦¬í•œ íŒŒì¼ ì´ë¦„ì„ ì…ë ¥(preprocessed.csv)
- -c : ì›ë³¸ ë°ì´í„°ì˜ í†µê³„ íŒŒì¼ ì´ë¦„ ì…ë ¥(criteria.csv)
- -w : ìœˆë„ìš° ì‚¬ì´ì¦ˆ ì„¤ì •
- -p : ì˜ˆì¸¡ ìœˆë„ìš° ì‚¬ì´ì¦ˆ ì„¤ì •
- -hp : hyper parameter ì„¤ì •(-e, -b ê°™ì´ ì‚¬ìš©)
    - -e : epoch ì„¤ì •
    - -b : batch size ì„¤ì •hourly : ì‹œê°„ë‹¹
- -l : learningì˜ ì˜ë¯¸ë¡œ íŠ¹ì •í•œ ì¸ìì˜ ê°’(default)ìœ¼ë¡œ ë°ì´í„° ì „ì²˜ë¦¬ ì§„í–‰
    - -f, -c ì…ë ¥ í•„ìš”(defaultë¡œ ì‹¤í–‰)

`-l` ì˜µì…˜ì€ 1_Preprocessing_tool.pyì˜ `-p` ì™€ ë™ì¼

### main()

```python
import importlib
import argparse

preprocessing = importlib.import_module('Data_preprocessing')
training = importlib.import_module('Training')

def main():
    args = parse_arguments()

    if args.learning: 
        training.training(7, 1)

    else:
        # ë°ì´í„° ì½ì–´ì˜¤ê¸°
        df = training.read_data(args.filename)
    
        # í•™ìŠµ ë°ì´í„° / í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
        train, test = training.train_test_split(df)

        # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
        sc = training.data_scaling(train)

        # x_train, y_train, x_test ìƒì„±
        x_train, y_train = training.create_train(train, args.window_size, args.periods, sc)
        x_test = training.create_x_test(test, args.window_size, sc)

        # ëª¨ë¸ ìƒì„±
        lstm_model = training.lstm_arch(x_train, y_train, args.periods, args.epochs, args.batch_size)

        # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ 
        plot = training.lstm_performance(lstm_model, sc, x_test, test, args.epochs, args.batch_size)

        # ìŠ¤ì¼€ì¼ëŸ¬, ëª¨ë¸, ê·¸ë˜í”„ ì €ì¥
        training.save_output(sc, lstm_model, plot)

```

- `if args.learning` ì€ -l ì˜µì…˜(default ê°’)ì„ ì‚¬ìš©í–ˆì„ ê²½ìš° ì‹¤í–‰
- `training.training(7,1)`ì€ Training.pyì— ì¡´ì¬í•˜ëŠ” training(window_size, periods)ë¥¼ ì‹¤í–‰
    - `Training.py` ì€ main()ì— ì •ì˜ë˜ì–´ ìˆëŠ” í•¨ìˆ˜ë“¤ì˜ ë‚´ìš©ë“¤ì´ ì¡´ì¬í•˜ëŠ” íŒŒì¼
- else ë¶€ë¶„ì€ Training.pyë¥¼ ì´ìš©í•˜ì—¬ ì„¤ëª…

---

## Training.py

`Training.py` ì€ 2_Learning_LSTM.pyë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•œ í•¨ìˆ˜ë“¤ ì •ì˜ëœ íŒŒì¼ì´ë‹¤.

### ìˆœì„œ

1. ë°ì´í„° ì½ì–´ì˜¤ê¸°
    1. preprocessed.csv
2. train / test split (7:3)
3. Scaling
4. x_train, y_train, x_test ìƒì„±
5. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
6. Learning_lstm directoryì— ê²°ê³¼ê°’ ì €ì¥
    1. ìŠ¤ì¼€ì¼ëŸ¬ : scaler.pkl
    2. LSTM ëª¨ë¸ : lstm_model.pkl
    3. LSTM ì„±ëŠ¥ í‰ê°€ ê·¸ë˜í”„ : lstm_performance_graph.tiff

### Import

```python
from keras.models import Sequential
from keras.layers import Dense, LSTM
from tensorflow.keras.optimizers import SGD
from sklearn.preprocessing import MinMaxScaler
from keras.metrics import MeanSquaredError
import matplotlib.pyplot as plt
from joblib import dump
import pandas as pd
import numpy as np
import sys
import os
```

- `from keras.models import Sequential`
    - Kerasì—ì„œ ëª¨ë¸ì„ ì¸µ(layer)ë³„ë¡œ ë§Œë“œëŠ” ë°©ë²• ì œê³µ, ì„ í˜•ì ìœ¼ë¡œ ì¸µì„ ìŒ“ì„ ìˆ˜ ìˆê²Œ í•´ì¤Œ
- `from keras.layers import Dense, LSTM`
    - Kerasì—ì„œ ì œê³µí•˜ëŠ” ì¸µ(layer) ì¤‘ í•˜ë‚˜ì¸ ì™„ì „ ì—°ê²° ì¸µìœ¼ë¡œ, í•´ë‹¹ ì¸µì˜ ê° ë‰´ëŸ°ì´ ì´ì „ ì¸µì˜ ëª¨ë“  ë‰´ëŸ°ê³¼ ì—°ê²°
    - ì‹œê³„ì—´ ë¶„ì„ ëª¨ë¸ ì œê³µ
- `from tensorflow.keras.optimizers import SGD`
    - SGD(í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•) ìµœì í™” ì•Œê³ ë¦¬ì¦˜ ì œê³µ
- `from sklearn.preprocessing import MinMaxScaler`
    - íŠ¹ì • ë²”ìœ„ ìŠ¤ì¼€ì¼ë§ ë°©ì‹ì¸ MinMaxScaler ì œê³µ
- `from keras.metrics import MeanSquaredError`
    - íšŒê·€ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€í•˜ëŠ” MSE(í‰ê·  ì œê³± ì˜¤ì°¨) ì œê³µ
- `from joblib import dump`
    - Python ê°ì²´ë¥¼ ë””ìŠ¤í¬ë¡œ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‚¬ìš©, scikit-learn ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ë¡œë“œí•  ë•Œ ì‚¬ìš©

### í™˜ê²½ë³€ìˆ˜ ì„¤ì •

```python
os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]="0"
```

CUDAë¥¼ ì‚¬ìš©í•˜ëŠ” GPU ë””ë°”ì´ìŠ¤ ì„¤ì • ì½”ë“œ

1. **`os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"`**
    1. CUDA ë””ë°”ì´ìŠ¤ì˜ ìˆœì„œë¥¼ PCI ë²„ìŠ¤ ID ìˆœì„œë¡œ ì„¤ì • ì¦‰, CUDAê°€ ë””ë°”ì´ìŠ¤ë¥¼ ì¸ì‹í•˜ê³  ì‚¬ìš©í•˜ëŠ” ìˆœì„œë¥¼ PCI ë²„ìŠ¤ IDì˜ ìˆœì„œë¡œ ì§„í–‰
    2. í•´ë‹¹ ì½”ë“œë¥¼ ì‘ì„±í•˜ë©´ ì—¬ëŸ¬ ê°œì˜ GPUê°€ ìˆì„ ê²½ìš°ì—ë„ ê° GPUë¥¼ ëª…í™•í•˜ê²Œ ì‹ë³„ì´ ê°€ëŠ¥
2. **`os.environ["CUDA_VISIBLE_DEVICES"]="0"`** 
    1. CUDA_VISIBLE_DEVICES í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •, ì´ ë³€ìˆ˜ëŠ” CUDAê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë””ë°”ì´ìŠ¤ë¥¼ ì§€ì •í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤. 
    2. "0"ì€ ì²« ë²ˆì§¸ GPUë¥¼ ì˜ë¯¸ ì¦‰, CUDAëŠ” ì´ ì½”ë“œ ì´í›„ì— ì²« ë²ˆì§¸ GPUë§Œ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •.

ìœ„ì˜ ì½”ë“œëŠ” ë‹¤ì¤‘ GPU ì‹œìŠ¤í…œì—ì„œ íŠ¹ì • GPUë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•˜ê³ ì í•  ë•Œ ìœ ìš©í•˜ë‹¤. 
    

### ë°ì´í„° ì½ì–´ì˜¤ê¸°(read_data)

```python
def read_data(filename):
    df = pd.read_csv(filename, 
                    parse_dates=['time'], index_col=0)
    col = df.columns[0]
    df[col] = df[col].astype(float)

    return df
```

- read_data í•¨ìˆ˜ì˜ ì¸ìˆ˜ëŠ” ì „ì²˜ë¦¬ ëœ íŒŒì¼ì¸ `preprocessed.csv`
- csv íŒŒì¼ í˜•ì‹

```
time,JM1_p
2020-01-01,4.145388888888888
2020-01-02,4.153791666666667
```

pd.read_csvì˜ ì¸ìˆ˜ì¸ `parse_dates` ëŠ” `True` ë¡œ ì„¤ì •í•  ê²½ìš° ì¸ë±ìŠ¤ë¥¼ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜

list í˜•ì‹ìœ¼ë¡œ ë„£ì„ ê²½ìš°(í•´ë‹¹ ì½”ë“œ [â€™timeâ€™]) ë¦¬ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ” ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜

`index_col` ì€ ì¸ë±ìŠ¤ì— ë„£ì–´ì¤„ ì»¬ëŸ¼ì„ ì§€ì •

ì¦‰, dfëŠ” ê¸°ì¡´ preprocessed.csvì— time ì»¬ëŸ¼ì— ì¡´ì¬í•˜ëŠ” ê°’ì„ datetimeìœ¼ë¡œ ë³€ê²½í•œ í›„ Indexë¡œ ì‚¬ìš©í•œë‹¤. ê·¸ëŸ¬ë¯€ë¡œ `df.columns[0]` ëŠ” JM1_pê°€ ëœë‹¤. ì´í›„ JM1_pì˜ ë°ì´í„° íƒ€ì…ì€ floatí˜•ìœ¼ë¡œ ë³€í™˜

- read_data í•¨ìˆ˜ ì‹¤í–‰ í›„ csv íŒŒì¼ êµ¬ì¡°

```
                      JM1_p
time                       
2020-01-01  4.145388888888888
2020-01-02  4.153791666666667
```

| index | col[0] |
| --- | --- |
| time | JM1_p |

### í•™ìŠµ ë°ì´í„° / í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  (7:3)

```python
def train_test_split(df):
    train_size = int(0.7 * len(df))
    train = df.iloc[:train_size]
    test = df.iloc[train_size:]

    return train, test
```

- read_dataí•¨ìˆ˜ê°€ ë°˜í™˜í•˜ëŠ” dfë¥¼ ì¸ìˆ˜ë¡œ ë°›ì•„ ëª¨ë¸ í•™ìŠµì„ ì§„í–‰í•˜ê¸° ìœ„í•œ train / test ë°ì´í„° ë¶„í•  ì§„í–‰
- í•´ë‹¹ í•¨ìˆ˜ì—ì„œëŠ” ë¶„í•  ë¹„ìœ¨ì„ `train : test = 7 : 3` ë¡œ ì„¤ì •
- 2_Learning_LSTM.py

```python
# í•™ìŠµ ë°ì´í„° / í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
train, test = training.train_test_split(df)
```

ê°ê° ë¹„ìœ¨ì— ë§ê²Œ train, test ë³€ìˆ˜ë¡œ ë°ì´í„°ê°€ ë“¤ì–´ê°

### ë°ì´í„° ìŠ¤ì¼€ì¼ë§

```python
def data_scaling(train):
    train_data = train.values
    sc = MinMaxScaler(feature_range=(0, 1)) # ì •ê·œí™” 
    sc = sc.fit(train_data) 

    return sc
```

`train_test_split` ë¥¼ í†µí•´ ì–»ì€ train ë°ì´í„°ë¥¼ data_scaling ì¸ìˆ˜ë¡œ í•˜ì—¬ MinMaxScaler ì •ê·œí™” ì§„í–‰

- **MinMaxScaler**
    
    ### ë°ì´í„° ìŠ¤ì¼€ì¼ë§(Data Scaling)
    
    **ì„œë¡œ ë‹¤ë¥¸ ë³€ìˆ˜ì˜ ê°’ ë²”ìœ„ë¥¼ ì¼ì •í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë§ì¶”ëŠ” ì‘ì—… ì˜ë¯¸**
    
    ê°’ì„ ì¡°ì •í•˜ëŠ” ê³¼ì •ì´ê¸° ë•Œë¬¸ì— ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì ìš©
    
    ### MinMaxScaler
    
    Scaleì„ ì¡°ì •í•˜ëŠ” ì •ê·œí™” í•¨ìˆ˜ë¡œ, ëª¨ë“  ë°ì´í„°ê°€ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ì„ ê°–ë„ë¡ í•´ì£¼ëŠ” í•¨ìˆ˜
    
    ì¦‰, ìµœëŒ“ê°’ì€ 1, ìµœì†Ÿê°’ì€ 0ìœ¼ë¡œ ë°ì´í„°ì˜ ë²”ìœ„ë¥¼ ì¡°ì •
    
    **ì•Œê³ ë¦¬ì¦˜ ì„±ëŠ¥ í–¥ìƒ**
    
    ML ì•Œê³ ë¦¬ì¦˜ì€ ì…ë ¥ ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ì— ë¯¼ê°í•˜ê¸° ë•Œë¬¸ì— ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒ
    
    **ì´ìƒì¹˜ ì²˜ë¦¬**
    
    ì´ìƒì¹˜ëŠ” ë°ì´í„°ì˜ ì¼ë°˜ì ì¸ ë¶„í¬ë¥¼ ì™œê³¡ì‹œí‚¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìŠ¤ì¼€ì¼ë§ì„ í†µí•´ ëŒ€ë‹¤ìˆ˜ì˜ ë°ì´í„°ê°€ 0~1 ì‚¬ì´ì— ìˆìœ¼ë¯€ë¡œ ì´ìƒì¹˜ì˜ ì˜í–¥ì„ ì¤„ì´ëŠ” ë° ë„ì›€
    
    ### ì™œ í›ˆë ¨ ë°ì´í„°ë§Œ ìŠ¤ì¼€ì¼ë§?
    
    ëª¨ë¸ì„ í•™ìŠµí•  ë•Œ ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì…‹(train ë°ì´í„°ì…‹)ì˜ í†µê³„ì  íŠ¹ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ì„ ìˆ˜í–‰í•˜ê¸° ë•Œë¬¸ 
    
    ì´ëŠ” ëª¨ë¸ì´ í•™ìŠµí•  ë•Œ ë³´ì§€ ëª»í•œ ë°ì´í„°(test ë°ì´í„°ì…‹ or ìƒˆë¡œìš´ ë°ì´í„°)ë¥¼ ì˜ˆì¸¡í•  ë•Œ ì¼ê´€ì„± ìˆê²Œ ìŠ¤ì¼€ì¼ë§ì„ ì ìš©
    
    í•´ë‹¹ ë°©ì‹ì„ ì‚¬ìš©í•¨ìœ¼ë¡œì¨ ëª¨ë¸ì´ test ë°ì´í„°ë‚˜ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ì„œë„ ì¼ê´€ëœ ì˜ˆì¸¡ ìˆ˜í–‰ì´ ê°€ëŠ¥
    

### x_train, y_train, x_test ìƒì„±

í•´ë‹¹ ë¶€ë¶„ì€ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ LSTM ëª¨ë¸ì„ í•™ìŠµí•˜ê¸° ìœ„í•œ í•™ìŠµ ë°ì´í„°ì…‹ì„ ìƒì„±í•˜ëŠ” ì½”ë“œì´ë‹¤.

```python
# x_train, y_train ìƒì„±
def create_train(train,window_size, periods, sc):
    
    train_data = train.values
    train_len = len(train_data)
    
    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    train_scaled = sc.transform(train_data)
    
    # x, y í•™ìŠµë°ì´í„° ìƒì„±
    x_train = []
    y_train = []
    for i in range(train_len - window_size - periods + 1):
        x_train_end = i+window_size
        x_train.append(train_scaled[i:x_train_end, 0]) 
        y_train.append(train_scaled[x_train_end:x_train_end+periods, 0])
    
    # ë¦¬ìŠ¤íŠ¸ë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
    x_train, y_train = np.array(x_train), np.array(y_train)

    # x_trainë¥¼ í…ì„œë¡œ ë³€í™˜
    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

    return x_train, y_train

```

- create_train(train, window_size, periods, sc) ì¸ìˆ˜ ì„¤ëª…
    - train : train_test_split()ì—ì„œ 7ëŒ€3 ë¹„ìœ¨ë¡œ ë‚˜ëˆˆ train data
    - window_size
        - ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¶„ì„ í•  ë•Œ ì‚¬ìš©ë˜ëŠ” ê°œë…, ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ê° ë°ì´í„° í¬ì¸íŠ¸ë¥¼ íŠ¹ì • ê¸°ê°„ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡í•˜ëŠ”ë° ì‚¬ìš©
        - ì¦‰, ëª¨ë¸ì´ ê³¼ê±° ë°ì´í„°ë¥¼ ì‚´í´ë³¼ ì‹œê°„ ë²”ìœ„ë¥¼ í‘œí˜„
        - ì˜ˆë¥¼ ë“¤ì–´ window_sizeì˜ ê°’ì´ 10ì´ë¼ë©´ 10ê°œì˜ ì´ì „ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰
    - periods
        - ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì˜ˆì¸¡í•  ë¯¸ë˜ ì‹œì ì˜ ê¸°ê°„ ì„¤ì •
        - ì¦‰, periodsëŠ” ëª¨ë¸ì´ ì˜ˆì¸¡í•  ì‹œì ìœ¼ë¡œë¶€í„° ì–¼ë§ˆë‚˜ ë–¨ì–´ì§„ ë¯¸ë˜ì˜ ë°ì´í„°ë¥¼ ì˜ˆì¸¡í•  ê²ƒì¸ì§€ ê²°ì •
        - ì˜ˆë¥¼ ë“¤ì–´ periodsì˜ ê°’ì´ 3ì´ë¼ë©´ ëª¨ë¸ì€ ë‹¤ìŒ 3ê°œ ì‹œì ì— ëŒ€í•œ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ì˜ˆì¸¡
    - sc : ìŠ¤ì¼€ì¼ë§(MinMaxScaler)ì„ ì§„í–‰í•œ í›ˆë ¨ ë°ì´í„°

**ìˆœì„œ**

- train ë°ì´í„°ì˜ ê°’ì— ëŒ€í•œ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì²˜ë¦¬
    - data_scaling í•¨ìˆ˜ì—ì„œ fit ê³¼ì •ì„ í•˜ì˜€ì§€ë§Œ ìŠ¤ì¼€ì¼ë§ ê³¼ì •ì„ ì™„ë£Œí•˜ë ¤ë©´ transformë„ ìˆ˜í–‰

```python
# x, y í•™ìŠµë°ì´í„° ìƒì„±
    x_train = []
    y_train = []
    for i in range(train_len - window_size - periods + 1):
        x_train_end = i+window_size
        x_train.append(train_scaled[i:x_train_end, 0]) 
        y_train.append(train_scaled[x_train_end:x_train_end+periods, 0])
```

- x_train
    - ëª¨ë¸ì— ì…ë ¥ë  í•™ìŠµ ë°ì´í„°ë¡œ ê°ê°ì˜ ë°ì´í„° í¬ì¸íŠ¸ëŠ” ì´ì „ì˜ ë°ì´í„°ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì‹œí€€ìŠ¤, í•´ë‹¹ ì‹œí€€ìŠ¤ ê¸¸ì´ëŠ” `window_size` ì— ì˜í•´ ê²°ì •
- y_train
    - x_train ì´í›„ì— ì˜ˆì¸¡í•  ë¯¸ë˜ì˜ ë°ì´í„°ë¥¼ í‘œí˜„, ë¯¸ë˜ ë°ì´í„°ì˜ ê¸°ê°„ì€ `periods` ì— ì˜í•´ ê²°ì •
- ë°˜ë³µë¬¸ì—ì„œì˜ i : í˜„ì¬ ì‹œê°„ ì°½ì˜ ì‹œì‘ ì§€ì 
- x_train_end :  í˜„ì¬ ì‹œê°„ ì°½ì˜ ë, ì¦‰ iì— window_sizeë¥¼ ë”í•œ ê°’
- train_scaled[i:x_train_end, 0] : í˜„ì¬ ì‹œê°„ ì°½ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë¥¼ x_trainì— ì¶”ê°€
- train_scaled[x_train_end:x_train_end + periods, 0] :  í˜„ì¬ ì‹œê°„ ì°½ ì´í›„ì˜ periods í¬ê¸°ë§Œí¼ì˜ ë¯¸ë˜ ë°ì´í„°ë¥¼ y_trainì— ì¶”ê°€

ê²°ë¡  : `x_train` ì€ LSTM ëª¨ë¸ì— ì…ë ¥ë˜ê³ , í•´ë‹¹ ì‹œê°„ ì°½ ì´í›„ì˜ `y_train` ì€ ëª¨ë¸ì˜ ì‹¤ì œ ì˜ˆì¸¡ê°’ê³¼ ë¹„êµí•˜ì—¬ í•™ìŠµ ì´ë£¨ì–´ì§

- x, y í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•œ í›„ ëª¨ë¸í•™ìŠµì„ ìœ„í•´ numpy, tensor(x_train)ë¡œ ë³€í™˜ ì§„í–‰

```python
# x_test ìƒì„±
def create_x_test(test,window_size, sc):
    test_data = test.values
    test_len = len(test_data)    
    
    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    test_scaled = sc.transform(test_data)
    
    # x í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    x_test = []
    for i in range(test_len - window_size):
        x_test_end = i+window_size
        x_test.append(test_scaled[i:x_test_end, 0]) 
    
    # ë¦¬ìŠ¤íŠ¸ë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
    x_test =  np.array(x_test)

    # x_testë¥¼ í…ì„œë¡œ ë³€í™˜
    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

    return x_test
```

- create_x_test(test, window_size, sc) ì¸ìˆ˜ ì„¤ëª…
    - test : train_test_split í•¨ìˆ˜ì— ì˜í•´ ë°˜í™˜ëœ testë¥¼ ì¸ìˆ˜ë¡œ ì‚¬ìš©
    - window_size : create_trainì˜ window_sizeì™€ ë™ì¼
    - sc : ìŠ¤ì¼€ì¼ë§(MinMaxScaler)ì„ ì§„í–‰í•œ í›ˆë ¨ ë°ì´í„°
- ìƒì„¸ ì½”ë“œëŠ” create_train í•¨ìˆ˜ì™€ ë™ì¼

### ëª¨ë¸ ìƒì„±

```python
def lstm_arch(x_train, y_train, periods, epochs, batch_size):
    # ëª¨ë¸ êµ¬ì„± (LSTM ë ˆì´ì–´ 2ê°œ, í™œì„±í™”í•¨ìˆ˜: í•˜ì´í¼ë³¼ë¦­íƒ„ì  íŠ¸ ì‚¬ìš©)
    lstm_model = Sequential([
        LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1), activation='tanh'),
        LSTM(units=50, activation='tanh'),
        Dense(units=periods) 
    ])
    
    # ëª¨ë¸ ì»´íŒŒì¼ (optimizer : SGD, ì†ì‹¤í•¨ìˆ˜: MSE ì‚¬ìš©)
    lstm_model.compile(optimizer=SGD(learning_rate=0.01, decay=1e-7, momentum=0.9, nesterov=False), loss='mean_squared_error')
    
    # ëª¨ë¸ í•™ìŠµ
    lstm_model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0, shuffle=False)
    
    return lstm_model
```

- lstm_arch í•¨ìˆ˜ëŠ” LSTM ëª¨ë¸ì„ ìƒì„±í•˜ê³  í•™ìŠµì‹œí‚¤ëŠ” ì—­í• 

**lstm_arch í•¨ìˆ˜ ìƒì„¸ ë¶„ì„**

```python
    # ëª¨ë¸ êµ¬ì„± (LSTM ë ˆì´ì–´ 2ê°œ, í™œì„±í™”í•¨ìˆ˜: í•˜ì´í¼ë³¼ë¦­íƒ„ì  íŠ¸ ì‚¬ìš©)
    lstm_model = Sequential([
        LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1), activation='tanh'),
        LSTM(units=50, activation='tanh'),
        Dense(units=periods) 
    ])
```

- ë ˆì´ì–´ë¥¼ ì„ í˜•ìœ¼ë¡œ ìŒ“ì€ êµ¬ì¡°ë¥¼ ê°–ëŠ” Sequential ëª¨ë¸ ìƒì„±
- ì²« ë²ˆì§¸ LSTM ë ˆì´ì–´ë¥¼ ì¶”ê°€
    - units ë§¤ê°œë³€ìˆ˜ëŠ” LSTM ë ˆì´ì–´ì˜ ë‰´ëŸ° ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ„
    - return_sequences=Trueë¡œ ì„¤ì •í•˜ë©´ LSTM ë ˆì´ì–´ê°€ ê° ì‹œê°„ stepì—ì„œ ì¶œë ¥ì„ ë°˜í™˜
    - input_shapeëŠ” ì…ë ¥ ë°ì´í„°ì˜ ëª¨ì–‘
        - x_train.shape[1]ì€ ì‹œê°„ ì°½ì˜ ê¸¸ì´
    - ìœ„ LSTM ê°œë…ì—ì„œ ì–¸ê¸‰í–ˆë“¯ì´ í™œì„±í™” í•¨ìˆ˜ëŠ” tanh ì‚¬ìš©
- ë‘ ë²ˆì§¸ LSTM ë ˆì´ì–´
    - return_sequences ì„¤ì •í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ ë§ˆì§€ë§‰ ì‹œê°„ stepì—ì„œë§Œ ì¶œë ¥ ë°˜í™˜
- Dense ë ˆì´ì–´
    - Dense ë ˆì´ì–´ëŠ” ì¶œë ¥ ë ˆì´ì–´ë¡œ units=periodsë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ì„œ ëª¨ë¸ì€ periods í¬ê¸°ì˜ ì¶œë ¥ì„ ìƒì„±
    

```python
# ëª¨ë¸ ì»´íŒŒì¼ (optimizer : SGD, ì†ì‹¤í•¨ìˆ˜: MSE ì‚¬ìš©)
    lstm_model.compile(optimizer=SGD(learning_rate=0.01, decay=1e-7, momentum=0.9, nesterov=False), loss='mean_squared_error')
```

- ìµœì í™” ì•Œê³ ë¦¬ì¦˜
    - SGD(í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•) ì‚¬ìš©
- Hyper parameter ì„¤ì •
- loss ë³€ìˆ˜ëŠ” ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì˜ë¯¸í•˜ë©° MSE(í‰ê·  ì œê³± ì˜¤ì°¨)ë¥¼ ì‚¬ìš©

```python
# ëª¨ë¸ í•™ìŠµ
    lstm_model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0, shuffle=False)
```

- ìƒì„±í•œ ë°ì´í„°ì…‹ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë¸ í•™ìŠµì„ ì§„í–‰
- epochs : ì „ì²´ ë°ì´í„°ì…‹ ë°˜ë³µ íšŸìˆ˜
- batch_size : í•œ ë²ˆì— ëª¨ë¸ì´ ì²˜ë¦¬í•  ë°ì´í„° ìƒ˜í”Œ ê°¯ìˆ˜(ê±´ë„ˆ ë›°ëŠ” stepìœ¼ë¡œ ìƒê°)
- verbose = 0 : í•™ìŠµ ê³¼ì •ì„ ì¶œë ¥ x
- shuffle=False : ë°ì´í„°ë¥¼ ì„ì§€ ì•ŠìŒ

ìµœì¢…ì ìœ¼ë¡œ lstm_modelì„ ë°˜í™˜í•˜ë©°, ì´ëŠ” ì„±ëŠ¥ í‰ê°€ í•¨ìˆ˜ì—ì„œ ì´ìš©ëœë‹¤.

### ëª¨ë¸ ì„±ëŠ¥ í‰ê°€

```python
# ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
def lstm_performance(lstm_model, sc, x_test, test, epochs, batch_size):
    # ì˜ˆì¸¡
    preds = lstm_model.predict(x_test)
    # ì›ë˜ ê°’ìœ¼ë¡œ ë³€í™˜
    preds = sc.inverse_transform(preds)
    
    # ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ì„ ë¹„êµí•˜ê¸° ìœ„í•œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    predictions_plot = pd.DataFrame(columns=['actual', 'prediction'])
    predictions_plot['actual'] = test.iloc[0:len(preds), 0]
    predictions_plot['prediction'] = preds[:, 0]
    
    # RMSE ê³„ì‚°
    mse = MeanSquaredError()
    mse.update_state(np.array(predictions_plot['actual']), np.array(predictions_plot['prediction']))
    RMSE = np.sqrt(mse.result().numpy())
    
    # ê·¸ë˜í”„
    return (predictions_plot.plot(figsize=(15, 5), 
                                title=f'lstm performance\nepochs={epochs}, batch size={str(batch_size)}, RMSE={str(round(RMSE, 4))}'))
```

**ì˜ˆì¸¡**

- í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ x_testì— ëŒ€í•œ ì˜ˆì¸¡ê°’ ìƒì„±
- í•´ë‹¹ ì˜ˆì¸¡ê°’ì€ ìŠ¤ì¼€ì¼ë§ì´ ì ìš©ëœ ìƒíƒœì´ë¯€ë¡œ `sc.inverse_transform` ì„ ì‚¬ìš©í•˜ì—¬ ì›ë˜ ë°ì´í„°ì˜ ë‹¨ìœ„ë¡œ ë³€í™˜

**ì„±ëŠ¥ í‰ê°€**

- ì‹¤ì œê°’(actual)ê³¼ ì˜ˆì¸¡ê°’(prediction)ì„ ë¹„êµí•˜ê¸° ìœ„í•œ Dataframe ìƒì„±
- RMSE(í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œê°’ê³¼ ì˜ˆì¸¡ê°’ ì°¨ì´ í™•ì¸(ì†ì‹¤í•¨ìˆ˜)
    - ëª¨ë¸ ìƒì„± ë¶€ë¶„ì—ì„œì˜ ì†ì‹¤í•¨ìˆ˜ì¸ MSEëŠ” ìµœì í™” ë‹¨ê³„ì—ì„œì˜ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ê°„ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ì—¬ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ì‚¬ìš©

**ê·¸ë˜í”„**

- lstm_performance í•¨ìˆ˜ì˜ ë°˜í™˜ê°’ìœ¼ë¡œ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì„ ë¹„êµí•˜ëŠ” ê·¸ë˜í”„(ì‹œê°ì )ë¥¼ ìƒì„±

### ìŠ¤ì¼€ì¼ëŸ¬, ëª¨ë¸, ê·¸ë˜í”„ ì €ì¥

ìµœì¢…ì ìœ¼ë¡œ ì–»ì€ ê²°ê³¼ë¬¼ë“¤ì„ ì„¤ì •í•œ ê²½ë¡œì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.

```python
def save_output(sc, lstm_model, plot):
    # ì¶œë ¥ í´ë” ìƒì„±
    output_path = './Output/Learning_lstm'
    os.makedirs(output_path,exist_ok=True)

    dump(sc, f'{output_path}/scaler.pkl') # scaler ì €ì¥
    lstm_model.save(f'{output_path}/lstm_model.h5') # ëª¨ë¸ ì €ì¥
    plt.savefig(f'{output_path}/lstm_performance_graph.tiff') # ê·¸ë˜í”„ ì €ì¥
```

### ê¸°ë³¸ê°’ ì‹¤í–‰

```python
def training(window_size, periods):
    # ë² ìŠ¤íŠ¸ ëª¨ë¸ì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì‚¬ìš©
    epochs = 700
    batch_size = 32

    # ë°ì´í„° ì½ì–´ì˜¤ê¸°
    filename = './Output/Data_preprocessing/preprocessed.csv'
    df = read_data(filename)
    
    # í•™ìŠµ ë°ì´í„° / í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
    train, test = train_test_split(df)

    # ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    sc = data_scaling(train)

    #  x_train, y_train, x_test ìƒì„±
    x_train, y_train = create_train(train,window_size, periods, sc)
    x_test = create_x_test(test,window_size, sc)

    # ëª¨ë¸ ìƒì„±
    lstm_model = lstm_arch(x_train, y_train, periods, epochs, batch_size)

    # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
    plot = lstm_performance(lstm_model, sc, x_test, test, epochs, batch_size)

    # ìŠ¤ì¼€ì¼ëŸ¬, ëª¨ë¸, ê·¸ë˜í”„ ì €ì¥
    save_output(sc, lstm_model, plot)

```

- `-l` ì˜µì…˜ì„ í†µí•´ ê¸°ë³¸ê°’(hyper parameter)ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œ

---

## 3_Prediction.py

`1_Preprocessing_tool.py`ê³¼ `2_Learning_LSTM.py` ì„ í†µí•´ ë°ì´í„° ì „ì²˜ë¦¬ í›„ í•´ë‹¹ ë°ì´í„°ì…‹ìœ¼ë¡œ LSTM ëª¨ë¸ì„ í•™ìŠµ ì‹œí‚¤ëŠ” ê³¼ì •ì„ ì§„í–‰í–ˆë‹¤. ì´í›„ í•™ìŠµëœ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ë°ì´í„°ë¥¼ ë„£ì–´ì„œ ì˜ˆì¸¡(Prediction)ì„ ìˆ˜í–‰í•´ì•¼í•˜ëŠ” ë° í•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì´ë¥¼ ì§„í–‰í•œë‹¤.

`-a` ì˜µì…˜ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  customí•˜ì—¬ ì˜ˆì¸¡ì„ ì§„í–‰í•  ê²½ìš° ì „ì²˜ë¦¬ ~ ì˜ˆì¸¡(ì…ë ¥ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ê°’ ìƒì„±)

### **arguments**

- -h : parse_arguments()ì˜ ì¸ìë“¤ì— ëŒ€í•œ ì„¤ëª… ì¶œë ¥(help ê¸°ëŠ¥)
- -f : ì „ì²˜ë¦¬í•œ íŒŒì¼ ì´ë¦„ì„ ì…ë ¥(./Input/sample.csv)
- -c : ì›ë³¸ ë°ì´í„°ì˜ í†µê³„ íŒŒì¼ ì´ë¦„ ì…ë ¥(criteria.csv)
- -dp : ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰
    - ê¸°ë³¸ì€ ê²°ì¸¡ì¹˜ ë³´ì •
    - ë„êµ¬ ìƒíƒœê°€ -p(--prediction)ì´ë©´ í•˜ë£¨ ê°„ê²©ìœ¼ë¡œ ì‹œê°„ì„ ë³‘í•©
- -t : -dpì™€ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ì˜µì…˜ìœ¼ë¡œ ë°ì´í„°ì˜ ì‹œê°„ ê°„ê²©ì„ ë³€ê²½ ë° ì„ íƒ
- -w : -dpì™€ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” ì˜µì…˜ìœ¼ë¡œ ì£¼ë§ ë˜ëŠ” í‰ì¼ ë°ì´í„° êµ¬í•˜ê¸°
- -p : ë„êµ¬ë¥¼ ì˜ˆì¸¡ ìƒíƒœë¡œ ì„¤ì •(ì˜ˆì¸¡ì— ëŒ€í•œ ì¸ì)
- -d : ë„êµ¬ë¥¼ ì´ìƒ íƒì§€ ìƒíƒœë¡œ ì„¤ì •
- -a : íŠ¹ì • ê°’ìœ¼ë¡œ ì´ìƒíƒì§€ì™€ ì˜ˆì¸¡ ìˆ˜í–‰(ê¸°ë³¸ê°’ ì‹¤í–‰)

```python
def main():
    args = parse_arguments()

    # ì´ìƒíƒì§€, ì˜ˆì¸¡ 
    if args.all:
        abnormal_detection.abnormal_detection(args.filename, args.criteria) # ì´ìƒíƒì§€
        predict.prediction(args.filename, args.criteria) # ì˜ˆì¸¡ 
    else:
        # ë°ì´í„° ì½ì–´ì˜¤ê¸°
        df = abnormal_detection.read_data(args.filename) 
    
        # ë°ì´í„° ì „ì²˜ë¦¬ : ê²°ì¸¡ì¹˜ ë³´ì •, ì‹œê°„ ê°„ê²© ë³‘í•©, í‰ì¼/ì£¼ë§ ë°ì´í„°
        if df.isnull().any().any():
            df = preprocessing.Missing(df) # ê²°ì¸¡ì¹˜ ë³´ì •

        if args.data_preprocessing or args.prediction: # ì‹œê°„ ê°„ê²© ë³‘í•©
            time_interval = {'hourly': '1H', 'daily': '1D'}.get(args.time)
            df = preprocessing.TimeIntervalData(df, time_interval)

            # í‰ì¼ / ì£¼ë§ ë°ì´í„° êµ¬í•˜ê¸°    
            if args.week in ['weekday', 'weekend']: 
                df = preprocessing.week(df, args.week)
        
        # ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°
        sc, lstm_model = abnormal_detection.load_model_and_scaler()

        # ëª¨ë¸ì˜ ìœˆë„ìš° ì‚¬ì´ì¦ˆ ì°¾ê¸°
        window_size = lstm_model.layers[0].input_shape[1]
    
        # x_data ìƒì„±
        x_data = abnormal_detection.create_x_new_data(df, window_size, sc)

        # ì˜ˆì¸¡
        preds = abnormal_detection.predictions(x_data, lstm_model, sc)

        # ì´ìƒ íƒì§€
        if args.detection:
            # ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
            preds_df = abnormal_detection.create_time_series_data(df, preds)

            # ì´ìƒì¹˜ ì¶”ì¶œ
            abnormal_df = abnormal_detection.detection(preds_df, args.criteria)
    
            # ì´ìƒì¹˜ ë°ì´í„° ì €ì¥
            abnormal_detection.save_data(abnormal_df)       

        # ì˜ˆì¸¡
        if args.prediction: 
            # ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
            periods_df = predict.create_predictive_data(df, preds)

            # ì´ìƒì¹˜ ê²€ì¶œ
            abnormal_df = abnormal_detection.detection(pd.DataFrame(periods_df.iloc[:,0]), args.criteria)

            # ë ˆì´ë¸” ì±„ìš°ê¸°
            periods_df = predict.fill_label(periods_df, abnormal_df)

            # ì˜ˆì¸¡ ë°ì´í„° ì €ì¥
            predict.save_data(periods_df)

```

- ì´ˆê¸° if ì¡°ê±´ë¬¸ì€ `-a` ì˜µì…˜ì„ ì‚¬ìš©í•  ê²½ìš° ì‚¬ì „ì— ì •ì˜í•œ ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ìƒíƒì§€ ë° ì˜ˆì¸¡ì„ ì§„í–‰
- else êµ¬ë¬¸ì˜ í•¨ìˆ˜ë“¤ì€ `Abnormal_detection.py` ê³¼ `Training.py` ë¡œ ì„¤ëª…

---

## Abnormal_detection.py

í•´ë‹¹ ìŠ¤í¬ë¦½íŠ¸ëŠ” ê¸°ì¡´ Data_preprocessing.py íë¦„ê³¼ ìœ ì‚¬í•œ ë¶€ë¶„ì´ ì¡´ì¬í•˜ì—¬ ì½”ë“œ ë‚´ì—ì„œ ë‹¤ë¥¸ ë¶€ë¶„ë§Œ ì–¸ê¸‰ ë° ì‘ì„± 

### ìˆœì„œ

1. ë°ì´í„° ì½ì–´ì˜¤ê¸°(Raw data)
2. ê²°ì¸¡ì¹˜ ë³´ì •
3. **ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°**
4. **x_data ìƒì„±**
5. ì˜ˆì¸¡
6. ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
7. ì´ìƒì¹˜ ê²€ì¶œ
8. ì´ìƒì¹˜ ë°ì´í„° ì €ì¥
    1. ./Output/Prediction/abnormal.csv

### Import

```python
import importlib
preprocessing = importlib.import_module('Data_preprocessing')
training = importlib.import_module('Training')
from keras.models import load_model
from joblib import load
import pandas as pd
import numpy as np
import sys
import os 
```

ìœ„ì—ì„œ ì„¤ëª…í•˜ì§€ ì•Šì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ëª…

- from keras.models import load_model : ì´ì „ ê³¼ì •ì—ì„œ í•™ìŠµí•œ LSTM ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê¸°
    - ëª¨ë¸ ì €ì¥ íŒŒì¼ í˜•ì‹ : h5
- from joblib import load : ì´ì „ ê³¼ì •ì—ì„œ ì–»ì€ ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°
    - ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥ íŒŒì¼ í˜•ì‹ : pkl(pickle)

### ë°ì´í„° ì½ì–´ì˜¤ê¸°

```python
def read_data(file_name):
    df = pd.read_csv(file_name, index_col = 0) 

    # ë°ì´í„°í”„ë ˆì„ ì¸ë±ìŠ¤ë¥¼ ë°ì´íŠ¸íƒ€ì„ì¸ë±ìŠ¤ë¡œ ë³€í™˜
    df.index = pd.to_datetime(df.index)
    df.index.name = 'time'

    # values ì´ë¦„ ì¶”ì¶œ
    col = df.columns[0]

    # float ë³€í™˜
    df[col] = pd.to_numeric(df[col], errors='coerce') 
    df[col] = df[col].astype(float)
    
    # ì¸ë±ìŠ¤ ì •ë ¬
    df = df.sort_index(ascending=True) 
    return df
```

- read_data(file_name) í•¨ìˆ˜ëŠ” ë™ì¼í•˜ë¯€ë¡œ ì„¤ëª… ìƒëµ

### ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°

```python
def load_model_and_scaler():
    # ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°
    sc = load('./Output/Learning_lstm/scaler.pkl')

    # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° 
    lstm_model = load_model('./Output/Learning_lstm/lstm_model.h5')

    return sc, lstm_model
```

- ì´ì „ ê³¼ì •ì—ì„œ í•™ìŠµí•œ LSTM ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°

### x_data ìƒì„±

```python
def create_x_new_data(new_data, window_size, sc):
    data = new_data.values
    data_len = len(data)
    
    # í•™ìŠµ ë°ì´í„° ìŠ¤ì¼€ì¼ë§
    data_scaled = sc.transform(data)
    
    # x í•™ìŠµë°ì´í„° ìƒì„±
    x_data = []

    for i in range(data_len - window_size):
        x_data_end = i+window_size 
        x_data.append(data_scaled[i:x_data_end, 0])
 
    # ë¦¬ìŠ¤íŠ¸ë¥¼ ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜
    x_data =  np.array(x_data)

    # x_dataë¥¼ í…ì„œë¡œ ë³€í™˜
    x_data = np.reshape(x_data, (x_data.shape[0], x_data.shape[1], 1))
    
    return x_data
```

- create_x_new_data(new_data, window_size, sc) í•¨ìˆ˜ëŠ” ë™ì¼í•˜ë¯€ë¡œ ì„¤ëª… ìƒëµ

### ì˜ˆì¸¡í•˜ê¸°

```python
def predictions(x_data, lstm_model, sc):
    # ì˜ˆì¸¡
    preds = lstm_model.predict(x_data)
    # ì›ë˜ ê°’ìœ¼ë¡œ ë³€í™˜
    preds = sc.inverse_transform(preds)
    return preds
```

- predictions(x_data, lstm_model, sc) í•¨ìˆ˜ëŠ” ë™ì¼í•˜ë¯€ë¡œ ì„¤ëª… ìƒëµ

### ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±

```python
# ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
def create_time_series_data(df, preds):
    # values ì´ë¦„ ì¶”ì¶œ
    col = df.columns[0]

    # ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
    preds_df = pd.DataFrame(columns=[col],
                            index=(df.loc[:, col][0:len(preds)]).index)
    preds_df[col] = preds[:, 0]

    return preds_df
```

- ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
    - ì£¼ì–´ì§„ Dataframeì˜ ì²« ë²ˆì§¸ ì»¬ëŸ¼ì— ì˜ˆì¸¡ê°’ì„ ì±„ì›Œì„œ ìƒˆë¡œìš´ Dataframe ìƒì„±
    - ì´ë•Œ ì˜ˆì¸¡ê°’ì€ ì´ì „ ë°ì´í„°ì˜ ì‹œê°„ê³¼ ì¼ì¹˜í•´ì•¼ í•˜ë¯€ë¡œ, ì˜ˆì¸¡ê°’ì˜ ê¸¸ì´ ë§Œí¼ì„ ì‚¬ìš©í•˜ì—¬ ì¸ë±ìŠ¤ ìƒì„±
- ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì´ìœ ëŠ” ì´ìƒì¹˜ ê²€ì¶œ ë¶„ì„ì— í™œìš©ë  ìˆ˜ ìˆìŒ

### ì´ìƒì¹˜ ê²€ì¶œ

```python
def detection(preds_df, criteria):
    # í•™ìŠµ ë°ì´í„°ì˜ í†µê³„í‘œ ì½ì–´ì˜¤ê¸°
    table = pd.read_csv(criteria, index_col = 0) 
    
    # ì—´ ì¶”ì¶œ
    column_values = preds_df.iloc[:,0]

    # ì´ìƒì¹˜ ë°ì´í„° ìƒì„±
    if all(idx in table.index for idx in ['U_level', 'L_level']): # U_levelì™€ L_levelê°€ ìˆëŠ” ê²½ìš°
        U_level = table.loc['U_level']['Values'] # upper limit 
        L_level = table.loc['L_level']['Values'] # lower limit 
        abnormal_df = preds_df[(column_values <= L_level) | (column_values >= U_level)]
    
    elif 'U_level' in table.index: # U_levelë§Œ ìˆëŠ” ê²½ìš°
        U_level = table.loc['U_level']['Values']
        abnormal_df = preds_df[column_values >= U_level]
    
    elif 'L_level' in table.index: # L_levelë§Œ ìˆëŠ” ê²½ìš°
        L_level = table.loc['L_level']['Values'] 
        abnormal_df = preds_df[column_values <= L_level]
    
    
    if  abnormal_df.empty:
        print('ì´ìƒì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.')
    
    return abnormal_df
```

- Data_processing.pyì—ì„œ ì‘ì„±í•œ Anomalous í•¨ìˆ˜(ì´ìƒì¹˜ ë³´ì •)ê³¼ ìœ ì‚¬ í•¨ìˆ˜
- ê¸°ì¡´ê³¼ ë‹¤ë¥¸ ì ì€ ì´ìƒì¹˜ ë°ì´í„°ë¥¼ ìƒì„±í•œ í›„ ìƒˆë¡œìš´ Dataframeì— ì €ì¥
- ì´ìƒì¹˜ê°€ ì—†ëŠ” ê²½ìš° â€œì´ìƒì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤â€ ì¶œë ¥
- ì´ìƒì¹˜ê°€ ì¡´ì¬í•  ê²½ìš° ì´ìƒì¹˜ë¥¼ ë‹´ì€ Dataframeì¸ abnormal_df ë°˜í™˜

### ì´ìƒì¹˜ ë°ì´í„° ì €ì¥

```python
def save_data(abnormal_df):
    # í´ë” ìƒì„±
    output_path = './Output/Prediction'
    os.makedirs(output_path, exist_ok=True)
     
    # ì´ìƒì¹˜ ë°ì´í„° ì €ì¥
    abnormal_df.to_csv(f'{output_path}/abnomal.csv')
```

- ì´ìƒì¹˜ ë°ì´í„°ë¥¼ í•´ë‹¹ ê²½ë¡œì— ì €ì¥

### ê¸°ë³¸ê°’ ì‹¤í–‰

```python
def abnormal_detection(file_name,criteria):
    # íŒŒì¼ ì½ì–´ì˜¤ê¸°
    df = read_data(file_name)

    # ë°ì´í„° ì „ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    if df.isnull().any().any():
        df = preprocessing.Missing(df)

    # ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°
    sc, lstm_model = load_model_and_scaler()

    # ëª¨ë¸ì˜ ìœˆë„ìš° ì‚¬ì´ì¦ˆ ì°¾ê¸°
    window_size = lstm_model.layers[0].input_shape[1]
    
    # x_data ìƒì„±
    x_data = create_x_new_data(df, window_size, sc)

    # ì˜ˆì¸¡
    preds = predictions(x_data, lstm_model, sc)

    # ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
    preds_df = create_time_series_data(df, preds)

    # ì´ìƒì¹˜ ì¶”ì¶œ
    abnormal_df = detection(preds_df, criteria)
    
    # ì´ìƒì¹˜ ë°ì´í„° ì €ì¥
    save_data(abnormal_df)
```

- abnormal_detection(file_name, criteria) : `-a` ì˜µì…˜ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜

---

## Prediction.py

ì´ìƒ íƒì§€(Abnormal_detection.pyì— ì •ì˜) í›„ ì˜ˆì¸¡ ê³¼ì •ì„ ìˆ˜í–‰í•œë‹¤. 

- 3_Prediction.py ì˜ˆì¸¡ ì½”ë“œ íë¦„

```
        if args.prediction: 
            # ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
            periods_df = predict.create_predictive_data(df, preds)

            # ì´ìƒì¹˜ ê²€ì¶œ
            abnormal_df = abnormal_detection.detection(pd.DataFrame(periods_df.iloc[:,0]), args.criteria)

            # ë ˆì´ë¸” ì±„ìš°ê¸°
            periods_df = predict.fill_label(periods_df, abnormal_df)

            # ì˜ˆì¸¡ ë°ì´í„° ì €ì¥
            predict.save_data(periods_df)
```

- Abnormal_detection.pyì˜ detection í•¨ìˆ˜ë¥¼ ì´ìš©í•œ ì´ìƒì¹˜ ê²€ì¶œ ë¶€ë¶„ì´ ìˆëŠ” ì´ìœ ëŠ” ìƒì„±ëœ ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„°(periods_df)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ë¥¼ ê²€ì¶œí•˜ëŠ” ë° ì´ë•Œ ì‚¬ìš©, ì´í›„ Dataframe ë°˜í™˜

### ì˜ˆì¸¡ ë°ì´í„° ìƒì„±

```python
def create_predictive_data(df, preds):
    col = df.columns[0]
    last_index = df.index[-1] # # ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤ ì°¾ê¸°
    periods = preds.shape[1] # # prediction window size ì°¾ê¸°
    freq = pd.infer_freq(df.index) # ì‹œê°„ ê°„ê²© ì°¾ê¸°

    # ë°ì´íŠ¸íƒ€ì„ ìƒì„±
    preds_index = pd.date_range(str(last_index), periods=(periods+1), freq=freq)
    preds_index = preds_index[1:] # ì˜ˆì¸¡ê°’ì˜ ë°ì´íŠ¸íƒ€ì„ ì¶”ì¶œ

    # ì˜ˆì¸¡ê°’ì˜ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
    periods_df = pd.DataFrame(index=preds_index, columns=[col, 'label'])
    periods_df[col] = list(preds[-1])
    periods_df.index.name =  'time'

    return periods_df
```

- ê¸°ì¡´ dfì™€ ì˜ˆì¸¡ê°’ predë¥¼ ì´ìš©í•˜ì—¬ ì˜ˆì¸¡ê°’ì„ í¬í•¨í•œ Dataframeì¸ periods_df ìƒì„±í•˜ê³  ì´ë¥¼ ë°˜í™˜

### ë ˆì´ë¸” ì±„ìš°ê¸°

```python
def fill_label(periods_df, abnormal_df):
    col = periods_df.columns[0]
    # ì˜ˆì¸¡ ë°ì´í„°ì™€ ì´ìƒì¹˜ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ì—ì„œ êµì§‘í•© ì¶”ì¶œ
    common_index = periods_df.index.intersection(abnormal_df.index)
    # label ì±„ìš°ê¸°
    periods_df.loc[common_index,'label'] = 'Abnormal' # êµì§‘í•©: Abnormal
    periods_df['label'].fillna('Normal', inplace=True) # ì•„ë‹ˆë©´ :Normal

    for index, row in periods_df.iterrows():
        print(f'\nì‹œê°„: {index} - ì˜ˆì¸¡ ê°’: {row[col]}, ë ˆì´ë¸”: {row["label"]}')

    return periods_df
```

- ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„°(periods_df)ì™€ ì´ìƒì¹˜ë¥¼ í¬í•¨í•˜ëŠ” Dataframeì¸ abnormal_dfë¥¼ ì¸ìˆ˜ë¡œ ë°›ì•„ì„œ ë ˆì´ë¸”ì„ ì±„ìš°ëŠ” í•¨ìˆ˜
- ë‘ ê°œì˜ Dataframeì˜ indexë¥¼ êµì§‘í•©ìœ¼ë¡œ í•˜ì—¬ ì¶”ì¶œí•˜ëŠ”ë°, ì´ ê³¼ì •ì„ í†µí•´ ì´ìƒì¹˜ê°€ ì˜ˆì¸¡ê°’ì˜ ì–´ëŠ ë¶€ë¶„ì— ìœ„ì¹˜í•´ìˆëŠ”ì§€ë¥¼ íŒŒì•… ê°€ëŠ¥
- ì¦‰, abnormal_dfëŠ” ì´ìƒì¹˜ê°€ ì¡´ì¬í•˜ëŠ” íŠ¹ì • ì‹œê°„ì„ ì¸ë±ìŠ¤ë¡œ í•˜ëŠ” Dataframeì´ë¯€ë¡œ periods_df ì˜ ì¸ë±ìŠ¤ì—ì„œ abnormal_dfì˜ ì¸ë±ìŠ¤ì™€ ë™ì¼í•˜ë‹¤ë©´ `Abnormal` ë¡œ í‘œì‹œí•˜ê³  ì•„ë‹ˆë¼ë©´ `Normal` ë¡œ í‘œì‹œ
(label ì†ì„±ì— ê°’ í‘œì‹œ)

### ì˜ˆì¸¡ ë°ì´í„° ì €ì¥

```python
def save_data(periods_df):
    # ì¶œë ¥ í´ë” ìƒì„±
    output_path = './Output/Prediction'
    os.makedirs(output_path,exist_ok=True)

    # ì˜ˆì¸¡í•œ ë°ì´í„° ì €ì¥
    periods_df.to_csv(f'{output_path}/prediction.csv')
```

- ìœ„ ê³¼ì •ì—ì„œ label ì†ì„±ì—ì„œ ì´ìƒì¹˜ê¹Œì§€ ë¼ë²¨ë§í•œ ê²°ê³¼ë¬¼ì„ ì„¤ì •í•œ ê²½ë¡œì— ì €ì¥

### ê¸°ë³¸ê°’ ì‹¤í–‰

```python
def prediction(file_name, criteria):
    # ë°ì´í„° ì½ì–´ì˜¤ê¸°
    df = read_data(file_name)
    # ë°ì´í„° ì „ì²˜ë¦¬: ê²°ì¸¡ì¹˜ ì²˜ë¦¬, ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë³‘í•©
    if df.isnull().any().any():
        df = preprocessing.Missing(df)
    df = preprocessing.TimeIntervalData(df, '1D') # 1ì‹œê°„ ê°„ê²©ìœ¼ë¡œ ë³‘í•© 

    # ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¶ˆëŸ¬ì˜¤ê¸°
    sc, lstm_model = abnormal_detection.load_model_and_scaler()

    # ëª¨ë¸ì˜ ìœˆë„ìš° ì‚¬ì´ì¦ˆ ì°¾ê¸°
    window_size = lstm_model.layers[0].input_shape[1]
    
    # x_data ìƒì„±
    x_data = abnormal_detection.create_x_new_data(df, window_size, sc)

    # ì˜ˆì¸¡
    preds = abnormal_detection.predictions(x_data, lstm_model, sc)

    # ì˜ˆì¸¡ê°’ì— ëŒ€í•œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
    periods_df = create_predictive_data(df, preds)

    # ì´ìƒì¹˜ ê²€ì¶œ
    abnormal_df = abnormal_detection.detection(pd.DataFrame(periods_df.iloc[:,0]), criteria)

    # ë ˆì´ë¸” ì±„ìš°ê¸°s
    periods_df = fill_label(periods_df, abnormal_df)

    # ì˜ˆì¸¡ ë°ì´í„° ì €ì¥
    save_data(periods_df)
```