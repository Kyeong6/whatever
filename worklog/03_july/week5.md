# 업무내용

- 통신 프로토콜 구성
- 프로젝트에서 사용할 기술 선택 이유

## 7/29

### 통신 프로토콜 구성

이상치 검출과 LSTM을 통한 예측값을 임베디드 기기로 보내줘야하는 과정이 존재하여 임베디드를 담당하는 타회사와의 **통신 프로토콜**을 구성한다.

**전달**  
PC → 임베디드 장치

**상세 내용**  
자세한 내용은 생략
<br/></br>
### 프로젝트에서 사용할 기술 선택 이유

**1.데이터베이스 선정 : SQLite3를 왜 사용하나?**

현재는 프로젝트에 Mini PC를 사용하여 진행하고있지만, 최종적으로 임베디드 장치를 이용해서 **“스마트 유량계”**를 개발하는 것이 목표이기 때문에 MySQL와 같이 서버가 필요하지 않은 서버리스인 SQLite3를 채택하였다.(SQLite3 같은 경우 임베디드 시스템에서 많이 사용한다.)

**SQLite3의 이점**

1. **경량성과 성능**
- **경량성**: SQLite3는 매우 작은 크기의 라이브러리로, 자원이 제한된 임베디드 시스템에서도 쉽게 사용할 수 
있다.(MySQL과 같은 서버 기반 데이터베이스는 더 많은 리소스와 복잡한 관리가 필요하다.)
- **빠른 속도**: SQLite는 작은 데이터베이스에 대해 매우 빠른 읽기 및 쓰기 성능을 제공한다. 
(임베디드 시스템에서는 일반적으로 대용량 데이터 처리보다는 신속한 데이터 접근이 더 중요하기 때문에 적합하다.)

2. **자체 포함한 데이터베이스**
- **서버리스** : SQLite3는 자체 포함형 데이터베이스로, 별도의 데이터베이스 서버가 필요하지 않는다. 
(임베디드 시스템에서 매우 중요한 이점으로, 시스템 복잡성을 줄이고 유지보수를 용이하게 한다.)
- **단일 파일 데이터베이스**: 모든 데이터가 하나의 파일에 저장되므로, 파일 시스템에서 직접 관리할 수 있다. 
(임베디드 시스템에서 스토리지 관리에 매우 유리하다.)

3. **낮은 메모리 및 CPU 사용량**
- **효율적인 자원 사용**: SQLite는 매우 낮은 메모리와 CPU 사용량을 필요로 한다. 
(임베디드 시스템과 같은 자원이 제한된 환경에서 중요하다.)
- **빠른 응답 시간**: 작은 크기의 데이터베이스와 최적화된 내부 알고리즘 덕분에, 데이터에 빠르게 접근할 수 있다.

**2.스케줄러 선정 : APScheduler vs Airflow**

현재 프로젝트에서 특정 시간에 실행해야할 작업들이 존재한다. (이상치 검출, 예측값 도출…)

이걸 도와주는 라이브러리(APSheduler)와 프레임워크(Airflow)에 관한 간단하게 설명하자면 다음과 같다.

- **APScheduler (Advanced Python Scheduler)**
    - **주요 기능:** 파이썬 기반의 스케줄러로, 작업을 특정 시간이나 주기에 실행할 수 있게 해준다.
    - **특징:** 경량이며, 사용이 간편하고 자원이 제한된 환경에서도 사용 가능하다.
- **Apache Airflow**
    - **주요 기능:** 복잡한 데이터 파이프라인 및 워크플로우를 관리하고 스케줄링하는 도구이다.
    - **특징:** 복잡한 작업 간의 종속성 관리가 가능하며, 웹 기반 UI를 통해 작업 흐름을 시각화하고 모니터링할 수 있다. 주로 대규모 데이터 처리와 분석에 사용된다.

위 내용을 요약하면, APScheduler는 간단하고 가벼운 스케줄링 작업에 적합하고, Airflow는 복잡한 워크플로우 관리에 적합하다는 것을 알 수 있다. 결국 해당 프로젝트는 최종적으로 임베디드 장치에 적용하는 것이 목표이므로 **APScheduler**를 적용하는 것이 타당하다는 것을 알 수 있다.   
추가적으로 타당한 이유를 자세하게 설명하자면 다음과 같다. 

**Airflow**

- 장점:
    - 복잡한 워크플로우 관리 : DAG를 통해 작업간의 복잡한 종속성 및 조건부 실행 처리 가능
    - 확장성 : 다양한 서비스 및 도구와 쉽게 통합할 수 있는 플러그인(기능) 제공
    - 사용자 인터페이스 : 웹 기반 UI를 제공하여 DAG를 시각화하고 작업 진행 상황을 모니터링하여 워크플로우 관리를 쉽게 관리 가능
- 단점:
    - 자원 사용량 : 위에 정리한 장점을 수행하기 위한 상당한 시스템 자원(CPU, MEM, 스토리지)이 필요
    - 복잡한 설정 : 초기 설정 및 구성 과정이 복잡

**APScheduler**

- 장점:
    - 경량 : APScheduler는 경량이며 최소한의 시스템 자원만 필요
    - 간단한 API : 작업을 예약하기 위한 간단한 API를 제공
- 단점:
    - 단순한 작업에 적합 : APScheduler는 단순한 스케줄링 작업에 적합하며 Airflow처럼 복잡한 워크플로우 종속성을 지원하지 않음
    - UI 없음 : 웹 UI가 없어 작업을 모니터링하고 관리하기 위해 자체적인 구현 필요

자세하게 알아본 결과 자원이 제한된 임베디드 시스템 환경에서는 경량성을 가진 **APScheduler**가 적합함을 알 수 있고, 추후 프로젝트의 작업(기능)이 복잡해질 경우 Airflow 도입을 고려할 수 있을 것 같다.

## 7/30

### SQLite 조사 및 학습

- 내용 정리

[https://pool-roast-1d0.notion.site/SQLite3-7b90856277074ce6a2af5b8cd52c5107?pvs=4](https://www.notion.so/SQLite3-7b90856277074ce6a2af5b8cd52c5107?pvs=21)

### CRUD 정리(함수)

- 테이블 생성
    - 실제값(1 min) 저장 
    - 예측값(1 hr) 저장 
    - 유량 이상치(1 min) 저장 
    - 압력 이상치(1 min) 저장
- 테이블 조회
    - LSTM 예측을 위한 조회 수행
- 테이블 적재
    - 실제값(1 min):
    - 이상치(1 min):
    - 예측값(1 hr):
- 데이터베이스 연결 종료

### 해결방안

현재 LSTM 모델을 1시간에 한 번씩 수행한 후 1일 1통신 개념을 적용해서 특정 시간에 임베디드 기기가 값을 가져가는 형식이다. 이럴 경우 1시간마다 예측한 값을 따로 저장을 해놔야하는데 이때 고려한 방식은 다음과 같다.

1. 결과 파일로 prediction.csv가 나오므로 prediction{num}.csv로 설정하여 구분한다. 통신이 끝난 경우 해당 파일들은 삭제한다.
2. 테이블을 생성하여 임시 저장장소로 사용하여, 통신이 끝난 경우 해당 테이블은 리셋을 진행한다. 

위 두 가지 방식 모두 생성하고 삭제(리셋)하는 과정이 존재하여 다른 방안을 생각해보았다.

프로젝트에서 결국 txt 파일을 이용해서 통신을 진행하는데 txt 파일에 미리 구성만 해놓고 임베디드 기기가 하루에 한 번 가져가면되는 방식을 생각했다.(가장 단순한 방식인데 복잡하게 생각했다.)

임베디드 기기에서 추가적인 구현을 진행하지 않게 1시간에 한 번씩 얻은 예측값을 txt 파일에 구성하고 최종적으로 마지막 시간의 예측값을 수행하고 난 뒤 시간 순으로 정렬을 진행해주는 방식을 채택했다. 

### Transform 정리(함수)

**txt 파일 직접 다루기 vs DataFrame 사용**

- txt 파일 직접 다루기
    - 장점 : 적은 메모리 사용량, 간단한 스크립트로 처리 가능
    - 단점 : 대량의 데이터 처리나 복잡한 조작 비효율적, 데이터 간의 관계 처리 및 분석 용이하지 않음
- DataFrame 사용
    - 장점 : 데이터를 효율적으로 조작하고 분석할 수 있는 기능 존재, 관계 처리 유용
    - 단점 : 메모리 사용량이 상대적으로 크다(데이터를 한 번에 메모리에 로드), 초기 데이터 로드 시 시간 
    소요

각 방법에는 장점과 단점이 존재하는데, 두 요소의 장점을 활용한 방식을 도입하고자 한다. 

**도입 선정 이유**

- 예측값 얻기(1 hr) : txt 파일 직접 다루기
- txt 파일 정렬 : DataFrame 사용

txt 파일을 직접 다루는 방식은 적은 양과 간단한 작업에 사용되므로 1시간 단위의 예측값(7 rows)를 txt 파일에 저장할 때는 해당 방식을 사용한다. 

마지막 예측값을 얻고 1일 1통신을 진행하기 전에는 예측값들(168 rows)이 시간 순으로 정렬이 되어있어야하는데 이때는 pandas 라이브러리를 이용해서 DataFrame을 생성하고 정렬한 후 txt 파일로 변환하는 작업을 한다.

1시간에 한 번씩 DataFrame을 사용하면 메모리 사용량이 txt 파일을 다루는 것보다 크기 때문에 정렬과 데이터 조작이 용이한 장점을 살려 하루에 한 번 DataFrame을 사용하는 것으로 채택했다. 

결국 이렇게 선정하는 이유는 임베디드라는 제한된 자원에서 효율적으로 기능이 실현되어야하기 때문이다.

## 7/31

### 업무보고 발표 내용

- 아키텍처 → 그림 자료
- 통신 프로토콜 작성 → 엑셀 파일 스크린샷
- 디렉토리 구조 → 노션 내용
- 코드 작성 원칙 → 집합 관계 설명(함수화 / 모듈화)
- 개발 진행 사항 → 그림 자료 / 개발 내용

### 개발 진행 사항

1. LSTM 예측 iD + 1h 구현 
2. database.py : SQLite에서 사용하는 명령어 모음
3. crud.py : database.py를 호출하여 crud 작업 수행(query 작성)
4. transform.py:
    - SensorDataTransform 클래스 : txt 파일 파싱, 데이터베이스 적재 구현
5. lstm_processor.py: 
    - LstmPredictionProcessor 클래스 : LSTM 예측 수행 후 DB 적재 및 txt 구성 구현(1 hr)